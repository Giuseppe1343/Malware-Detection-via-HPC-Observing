{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388b63c8-ea69-4730-8b9c-aaa14b49b1d2",
   "metadata": {},
   "source": [
    "# Shaping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d71d81-b6dc-414b-af51-6db693ec9cb3",
   "metadata": {},
   "source": [
    "### If you are monitoring your own samples, you should preprocess your .csv file with below part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebad8e-2c28-460e-8a9a-128cf53b4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_column_names = ['% Privileged Time', 'Handle Count', 'IO Data Bytes/sec', 'IO Data Operations/sec', \n",
    "                       'IO Other Bytes/sec', 'IO Other Operations/sec', 'IO Read Bytes/sec', 'IO Read Operations/sec', \n",
    "                       'IO Write Bytes/sec', 'IO Write Operations/sec', 'Page Faults/sec', 'Page File Bytes', \n",
    "                       'Page File Bytes Peak', 'Pool Nonpaged Bytes', 'Pool Paged Bytes', 'Priority Base', \n",
    "                       'Private Bytes', 'Thread Count', 'Virtual Bytes', 'Virtual Bytes Peak', \n",
    "                       'Working Set', 'Working Set - Private', 'Working Set Peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47800a19-2d9e-428c-9e64-a3e40555a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_file = 'SPC.csv'\n",
    "file_data = pd.read_csv(old_file, encoding='latin-1')\n",
    "\n",
    "file_data = file_data.iloc[:, 1:]\n",
    "file_data.columns = new_column_names\n",
    "file_data.replace({\" \":\"0.0\"}, inplace=True)\n",
    "file_data = file_data.astype(float)\n",
    "\n",
    "new_file = '300.csv'\n",
    "file_data.to_csv(new_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a26a08-80df-4009-ba1e-d800c18bf265",
   "metadata": {},
   "source": [
    "# Importing Libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba202afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81e535-42a3-4d8f-b306-d9c6dd1b6852",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d948bc-9e97-480d-9612-cf1d4c8140b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "folders = ['malware', 'safe']\n",
    "scaler = StandardScaler()\n",
    "malware_count = 0\n",
    "safe_count = 0\n",
    "\n",
    "for folder in folders:\n",
    "    num_files = len(os.listdir(folder))\n",
    "    \n",
    "    if(folder == 'malware'):\n",
    "        malware_count = num_files\n",
    "    else:\n",
    "        safe_count = num_files\n",
    "        \n",
    "    for i in range(1, num_files + 1):\n",
    "        file_path = os.path.join(folder, f'{i}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_scaled = scaler.fit_transform(df.values)\n",
    "        array = df_scaled.reshape(1, df_scaled.shape[0], df_scaled.shape[1])\n",
    "        data.append(array)\n",
    "\n",
    "data = np.concatenate(data)\n",
    "\n",
    "targets = np.concatenate([np.ones(malware_count), np.zeros(safe_count)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7408f-e7b5-401d-b51c-db60ad2530be",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32809a01-7a31-4ae6-9805-bb401b87ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 60\n",
    "features = 23\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.add(LSTM(240, input_shape=(timesteps, features), dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=120, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a461cc-9a8a-42cf-9424-067b7c974a6d",
   "metadata": {},
   "source": [
    "# Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedfb62-89d2-421e-885b-afe00f4bad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85508fe-7702-4042-838b-e188a13dcb47",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd50aa6-82cd-4088-be3f-54afcadb1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SSN.h5');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a408bbf-8e39-477c-bef4-aa16ee6c174a",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f28c4-0dff-4411-8e2c-b9f69a1bb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('SS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc7895-5151-4ac6-9d23-db6849ed8f98",
   "metadata": {},
   "source": [
    "# Testing Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fe046-8d94-43db-9af7-b2ef57b63f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_sample(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df_scaled = scaler.fit_transform(df.values)\n",
    "    return np.array([df_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b21da-a44d-4d47-976e-fb9b3793a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample = load_single_sample(\"B1.csv\")\n",
    "prediction = model.predict(single_sample)\n",
    "print(prediction)\n",
    "if prediction > 0.5:\n",
    "    print(\"Malware\")\n",
    "else:\n",
    "    print(\"Safe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
